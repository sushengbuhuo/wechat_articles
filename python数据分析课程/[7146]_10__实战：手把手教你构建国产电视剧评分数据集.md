<p data-nodeid="7603">在前面几讲，我们已经学习完了爬虫技术的三个基础环节：下载数据、提取数据以及保存数据。</p>
<p data-nodeid="7604">今天我们将通过一个综合的实战案例来将之前的内容都串联起来，帮你加深印象，更好地掌握 Python 爬虫技术。</p>
<h3 data-nodeid="7605">任务描述</h3>
<p data-nodeid="7606">近期，电视剧《司藤》热播，阿普闪购决定策划一场围绕国产口碑电视剧的周边特卖活动。为了最大化提升活动的成功率，需要对目前已经有的电视剧名称、演员和评分进行分析，以预判一个电视剧的评分走向。在一切预测与分析之前，首先就需要收集目前国产电视剧的相关数据，或者换句话说，需要构建一个国产电视剧和评分的数据集。</p>
<p data-nodeid="7607">作为数据分析部门的实习生，暂时还承担不了具体的分析和建模的工作，所以数据集构建这个任务就自然落到了你的肩上。</p>
<h4 data-nodeid="7608">任务说明</h4>
<p data-nodeid="7609">收集国产电视剧的数据，越全越好，至少收集评分、电视剧名称、主演信息三个信息。之后将数据存储在一个 csv 表中，表头如下：</p>
<ul data-nodeid="7610">
<li data-nodeid="7611">
<p data-nodeid="7612">title，代表电视剧的名称；</p>
</li>
<li data-nodeid="7613">
<p data-nodeid="7614">rating，代表电视剧的评分；</p>
</li>
<li data-nodeid="7615">
<p data-nodeid="7616">stars，代表电视剧的主演。</p>
</li>
</ul>
<p data-nodeid="7617">csv 的名字为，tv_rating.csv。</p>
<h3 data-nodeid="7618">初步分析 — 选择抓取的网站</h3>
<p data-nodeid="7619">在基于 Python 技术来构建数据集的方式中，首当其冲要做的事情就是选择要抓取的网站。选择的标准一般主要看网站是否具备我们想要的信息，以及是否方便抓取。</p>
<p data-nodeid="7620">这次我们要抓取的电视剧信息中，还有一个重要的考量因素就是**是否方便抓取多个页面，**毕竟一个网页一般都无法包含全部的电视剧信息。</p>
<p data-nodeid="7621">我们在下载 HTML 页面的环节往往需要下载多个页才能获取完整的数据。</p>
<p data-nodeid="7622">通过在搜索引擎搜索有电视剧列表的网站，我们筛选出了两个候选。</p>
<ul data-nodeid="7623">
<li data-nodeid="7624">
<p data-nodeid="7625">豆瓣电视剧主页：<a href="https://movie.douban.com/tv/#!type=tv&amp;tag=%E5%9B%BD%E4%BA%A7%E5%89%A7&amp;sort=recommend&amp;page_limit=20&amp;page_start=0?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="7841">https://movie.douban.com/tv/#!type=tv&amp;tag=%E5%9B%BD%E4%BA%A7%E5%89%A7&amp;sort=recommend&amp;page_limit=20&amp;page_start=0</a></p>
</li>
<li data-nodeid="7626">
<p data-nodeid="7627">电视剧网：<a href="http://dianshiju.tv/search.php?page=1&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="7867">http://dianshiju.tv/search.php?page=1&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</a></p>
</li>
</ul>
<p data-nodeid="7628">上述两个网站都有国产电视剧专区，我们接下来就逐一分析一下哪个更适合此次抓取任务。</p>
<h4 data-nodeid="7629">豆瓣电视剧主页分析</h4>
<p data-nodeid="7630">打开豆瓣电视剧主页，我们可以看到如下的列表。</p>
<p data-nodeid="10583" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKgliAHmHTAClfN3SouE4358.png" alt="Drawing 0.png" data-nodeid="10586"></p>

<p data-nodeid="7632">通过观察上述页面，可以看到一个比较明确的问题是：虽然有电视剧名和评分，但<strong data-nodeid="7879">缺乏主演信息</strong>。</p>
<p data-nodeid="7633">我们再来看它翻页的方式，拖到底部，可以看到一个加载更多的按钮，点击之后可以在底部加载更多的内容。没有传统的第一页，第二页这样的跳转链接。</p>
<p data-nodeid="14167" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKgmKAUyIrACE93sBbE8g086.png" alt="Drawing 1.png" data-nodeid="14170"></p>

<p data-nodeid="12972" class="">总结下来，豆瓣的电视剧主页存在两个明显问题：</p>


<ol data-nodeid="7635">
<li data-nodeid="7636">
<p data-nodeid="7637">在电视剧列表中缺乏主演信息；</p>
</li>
<li data-nodeid="7638">
<p data-nodeid="7639">无法通过 URL 来下载第二页和之后的内容，因为加载更多内容是在第一页中动态生成的，而这样动态生成的内容很难通过 Python 拿到。</p>
</li>
</ol>
<p data-nodeid="7640">虽然这两个问题通过一些技巧也能解决，但是平添了很多工作量，所以我们暂时不考虑抓取豆瓣。</p>
<h4 data-nodeid="7641">电视剧网主页分析</h4>
<p data-nodeid="7642">打开电视剧网，国产电视剧的主页，可以看到页面如下所示。</p>
<p data-nodeid="15361" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKgmuAIUYDADZYEXpQTec133.png" alt="Drawing 2.png" data-nodeid="15364"></p>

<p data-nodeid="7644">通过观察以上页面，可以发现该网页虽然弹窗广告比较多，但是我们想要的字段：标题、评分和主演信息在页面上都有显示，只要显示就说明我们可以通过爬虫拿到。</p>
<p data-nodeid="7645">现在我们来考察它的加载方式，拉到底部，可以看到该网页提供的是传统的翻页操作。如下所示：</p>
<p data-nodeid="16555" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKgnWAEx9lAAH6iRphN1Y708.png" alt="Drawing 3.png" data-nodeid="16558"></p>

<p data-nodeid="7647">我们点击第二页，发现跳转到了一个新的页面，该页面的 URL 和我们一开始访问的差不多，只是其中有一个参数：page 的值变为了 2。</p>
<p data-nodeid="7648">如下所示，我把有区分的地方加粗并加了下划线。</p>
<ul data-nodeid="21472">
<li data-nodeid="21473">
<p data-nodeid="21474">第一页：<a href="http://dianshiju.tv/search.php?page=1&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="21502">http://dianshiju.tv/search.php?page=1&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</a></p>
</li>
<li data-nodeid="21475">
<p data-nodeid="21476" class="">第二页：<a href="http://dianshiju.tv/search.php?page=1&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="21528">http://dianshiju.tv/search.php?page=2&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</a></p>
</li>
</ul>




<p data-nodeid="7654">这说明我们可以通过不断改变 URL 中的 page 参数的值，来访问第二页之后的内容。这样在后续写代码中，我们只需要写针对一个页面的抓取代码，然后用一个循环来不断执行该方法，并每次叠加 page 的值就能实现将所有电视剧的内容抓取下来。</p>
<p data-nodeid="7655">综上所述，电视剧网的页面更符合我们本次抓取的任务需求，我们后续就将该网页作为我们的抓取目标。</p>
<h3 data-nodeid="7656">数据获取 — 下载所需要的网页</h3>
<p data-nodeid="7657">接下来就开始抓取电视剧网的网页，出于数据集总量的考虑。通过和具体负责分析的同事沟通，这次抓取我们只需要抓前 100 页的内容即可。</p>
<h4 data-nodeid="7658">准备工作目录</h4>
<p data-nodeid="7659">首先，我们在你的课程目录中（也可以在桌面上）新建文件夹 chapter10 作为本次实战的主目录。之后打开 VS code, 选择文件 → 打开目录，选择 chapter10 这个目录并打开。</p>
<p data-nodeid="7660">打开后，新建 Notebook 并保存为 chapter10.ipynb，我们本讲的代码将在这个 notebook 文件中书写。</p>
<p data-nodeid="7661">因为我们这一次要下载的文件比较多（100 个 html），全部文件都放在同一个文件夹显然不是一个很好的选择，所以我们在 chapter10 中再建一个文件夹，用来保存下载的 HTML 文件。</p>
<p data-nodeid="7662">由于我们已经打开了 VS code ，所以我们直接在 VS code 左边的文件夹视图区右键 → 新建文件夹，然后输入文件夹名为 htmls，如下图所示。</p>
<p data-nodeid="22699" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/84/CioPOWCKgqKAF2GVAAGuKnuAs7E882.png" alt="Drawing 4.png" data-nodeid="22702"></p>

<p data-nodeid="7664">建立完后，我们 VS code 文件区是这个样子：有一个 notebook 文件，名为 chapter10 ，还有一个 htmls 的文件夹。</p>
<p data-nodeid="23873" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKgqqAc59IAADHMikDLlg643.png" alt="Drawing 5.png" data-nodeid="23876"></p>

<h4 data-nodeid="7666">单个网页下载</h4>
<p data-nodeid="7667">在 07 讲中，我们讲到过，下载网页有两种方式，一种是使用 urllib3 直接下载，另一种是动态网页，需要使用 selenium 这样的模拟浏览器的技术下载。所以网页下载的第一步，我们需要首先判断我们希望下载的网页需要使用哪种方式。</p>
<p data-nodeid="7668">我们首先测试是否可以直接使用 urllib3 直接下载电视剧网的网页，还记得我们在 07 讲中把 html 下载和保存到文件写成了两个函数：download_content 和 save_to_file， 这里我们直接拿来用即可。</p>
<p data-nodeid="7669">打开 chapter10.ipynb，新建 Cell，将 07 讲的两个函数先搬过来。</p>
<pre class="lang-python" data-nodeid="7670"><code data-language="python"><span class="hljs-keyword">import</span> urllib3
<span class="hljs-comment"># 第一个函数，用来下载网页，返回网页内容</span>
<span class="hljs-comment"># 参数 url 代表所要下载的网页网址。</span>
<span class="hljs-comment"># 整体代码和之前类似</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">download_content</span>(<span class="hljs-params">url</span>):</span>
    http = urllib3.PoolManager()
    response = http.request(<span class="hljs-string">"GET"</span>, url)
    response_data = response.data  
    html_content = response_data.decode()
    <span class="hljs-keyword">return</span> html_content
<span class="hljs-comment"># 第二个函数，将字符串内容保存到文件中</span>
<span class="hljs-comment"># 第一个参数为所要保存的文件名，第二个参数为要保存的字符串内容的变量</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_to_file</span>(<span class="hljs-params">filename, content</span>):</span>
    fo = open(filename,<span class="hljs-string">"w"</span>, encoding=<span class="hljs-string">"utf-8"</span>)
    fo.write(content)
    fo.close()
</code></pre>
<p data-nodeid="7671">按 shift + enter 运行，这样我们之后就可以使用这两个函数来下载网页了。</p>
<p data-nodeid="7672">现在我们来下载第一个电视剧，来测试 urllib3 的方案是否可以。</p>
<p data-nodeid="7673">新建 Cell，输入以下代码：</p>
<pre class="lang-python" data-nodeid="7674"><code data-language="python"><span class="hljs-comment">#&nbsp;将我们找到的电视剧网的网址存储在变量&nbsp;url&nbsp;中</span>
url&nbsp;=&nbsp;<span class="hljs-string">"http://dianshiju.tv/search.php?page=1&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD"</span>
<span class="hljs-comment">#&nbsp;将url&nbsp;对应的网页下载下来，并把内容存储在&nbsp;html_content&nbsp;变量中</span>
html_content&nbsp;=&nbsp;download_content(url)
<span class="hljs-comment">#&nbsp;将&nbsp;html_content&nbsp;变量中的内容存储在&nbsp;htmls&nbsp;文件夹中，文件名为&nbsp;tv1.html&nbsp;代表第一页</span>
save_to_file(<span class="hljs-string">"htmls/tv1.html"</span>,&nbsp;html_content)
</code></pre>
<p data-nodeid="25047">下载网页的步骤大家都很熟悉了，这里就不过多解释了。</p>
<p data-nodeid="25048">执行代码，之后可以看到 htmls 文件夹下多了 tv1.html，说明已经下载成功。</p>

<p data-nodeid="26221" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/84/CioPOWCKgrqACi3EAACrM-VEWEs789.png" alt="Drawing 6.png" data-nodeid="26224"></p>

<p data-nodeid="7677">接下来，我们点击 tv1.html 打开，来查看是否有我们需要的电视剧信息。回过头去看我们上文中发的截图，第一个电视剧的名称是《决胜法庭》。</p>
<p data-nodeid="7678">我们在 VS code 中搜索“决胜”，发现确实存在《决胜法庭》这个电视剧的信息。在下方还可以看到其评分：3.7。如下图所示。</p>
<p data-nodeid="27395" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKgu2AcykBAAOq7UheHSs461.png" alt="Drawing 7.png" data-nodeid="27398"></p>

<p data-nodeid="7680">说明电视剧网的内容<strong data-nodeid="8007">不是动态生成</strong>的，可以用 urllib3 进行下载。</p>
<h4 data-nodeid="7681">批量下载网页</h4>
<p data-nodeid="7682">现在第一个网页我们已经下载成功了。我们目标是下载 100 页的内容，所以剩余 99 页可以通过一个循环来下载。在我们之前的分析中，下载第二页和之后的内容只需要修改 URL 中的 page 的值即可。</p>
<p data-nodeid="7683">另外，在我们通过循环来批量下载内容的时候，还有一个很重要的注意事项，一般都会在每次下载之后等待几百毫秒的时间，再进行下一次下载，这样可以避免短时间内对网站发起大量的下载请求，浪费网站的带宽资源。</p>
<p data-nodeid="7684">在今天这个实战中，我们每次下载之后等待一秒再进行下一次下载。在 Python 中，我们可以通过 time 模块的 sleep 方法来使程序暂停固定的时间。</p>
<p data-nodeid="7685">新建 Cell ，输入如下的代码：</p>
<pre class="lang-python" data-nodeid="7686"><code data-language="python"><span class="hljs-keyword">import</span>&nbsp;time
<span class="hljs-comment">#&nbsp;第一页已经下载完毕，循环下载第2页到第100页的内容</span>
<span class="hljs-keyword">for</span>&nbsp;i&nbsp;<span class="hljs-keyword">in</span>&nbsp;range(<span class="hljs-number">2</span>,&nbsp;<span class="hljs-number">101</span>):
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;每次循环，使用&nbsp;replace&nbsp;函数将&nbsp;url&nbsp;字符串中&nbsp;page=1&nbsp;的部分替换为&nbsp;page&nbsp;+&nbsp;i，i为循环变量。</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;比如&nbsp;i=3时，将page=1&nbsp;替换为page=3,这样来下载第三页的内容</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将替换后的url&nbsp;存储在&nbsp;a_url&nbsp;变量中</span>
&nbsp;&nbsp;&nbsp;&nbsp;a_url&nbsp;=&nbsp;url.replace(<span class="hljs-string">"page=1"</span>,&nbsp;<span class="hljs-string">"page="</span>&nbsp;+&nbsp;str(i))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;打印出即将下载的URL</span>
&nbsp;&nbsp;&nbsp;&nbsp;print(<span class="hljs-string">"begin&nbsp;download:"</span>,&nbsp;a_url)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;下载当前页面的&nbsp;url&nbsp;的内容</span>
&nbsp;&nbsp;&nbsp;&nbsp;html_content&nbsp;=&nbsp;download_content(a_url)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;因为我们通过循环来下载，保存文件名也需要使用&nbsp;i&nbsp;来代表现在保存的是第几个网页。</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;比如&nbsp;i&nbsp;=&nbsp;3时，下载的是page=3的网页，最后则存储在&nbsp;htmls/tv3.html&nbsp;</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将本次循环要保存的文件名存储在&nbsp;file_name&nbsp;变量中</span>
&nbsp;&nbsp;&nbsp;&nbsp;file_name&nbsp;=&nbsp;<span class="hljs-string">"htmls/tv"</span>&nbsp;+&nbsp;str(i)&nbsp;+&nbsp;<span class="hljs-string">".html"</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将&nbsp;html&nbsp;文件的内容存储在&nbsp;file_name&nbsp;对应的文件夹里</span>
&nbsp;&nbsp;&nbsp;&nbsp;save_to_file(file_name,html_content)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;暂停一秒钟再继续下一次循环</span>
&nbsp;&nbsp;&nbsp;&nbsp;time.sleep(<span class="hljs-number">1</span>)
</code></pre>
<p data-nodeid="7687">执行上述程序，可以看到程序每隔一秒钟输出一行信息，如下所示。大概执行 100 秒后，程序执行结束，部分日志如下所示。</p>
<pre class="lang-java" data-nodeid="7688"><code data-language="java">begin download: http:<span class="hljs-comment">//dianshiju.tv/search.php?page=2&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</span>
begin download: http:<span class="hljs-comment">//dianshiju.tv/search.php?page=3&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</span>
begin download: http:<span class="hljs-comment">//dianshiju.tv/search.php?page=4&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</span>
begin download: http:<span class="hljs-comment">//dianshiju.tv/search.php?page=5&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</span>
begin download: http:<span class="hljs-comment">//dianshiju.tv/search.php?page=6&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</span>
begin download: http:<span class="hljs-comment">//dianshiju.tv/search.php?page=7&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</span>
begin download: http:<span class="hljs-comment">//dianshiju.tv/search.php?page=8&amp;searchtype=5&amp;order=commend&amp;tid=1&amp;area=&amp;year=&amp;letter=&amp;state=&amp;money=&amp;ver=&amp;jq=&amp;yuyan=%E5%9B%BD%E8%AF%AD</span>
</code></pre>
<p data-nodeid="7689">执行完毕后，我们在侧边栏打开 htmls 文件夹，可以看到我们的 100 个 html 文件已经保存成功。</p>
<p data-nodeid="28569" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKgvmAX5VSAAEHxc51fVk870.png" alt="Drawing 8.png" data-nodeid="28572"></p>

<p data-nodeid="7691">当然，不是下载出文件就算完了，我们还是需要查看一下这些 HTML 文件，看看是否包含我们预期的内容。比如以第 100 页为例。</p>
<p data-nodeid="7692">我们将上文提到的 URL 中的 page 改为 100，在浏览器中访问，第 100 页的电视剧如下所示。</p>
<p data-nodeid="29743" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKgwCAb59PADdwQLS-OPg049.png" alt="Drawing 9.png" data-nodeid="29746"></p>

<p data-nodeid="7694">第一个电视剧名为《疯人院也疯狂》，之后我们打开我们下载到对应的 html 文件：tv100.html。搜索“疯人院”，发现可以搜索到内容（如下图所示），所以大概率我们下载的 html 都对应了电视剧网站中的每一页的内容。</p>
<p data-nodeid="30917" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKgwyAFPcVAAUpG9jW8HY628.png" alt="Drawing 10.png" data-nodeid="30920"></p>

<p data-nodeid="7696">至此，我们所需要的数据就都已经下载到本地了，接下来我们要做的就是编写代码去提取出我们想要的信息。</p>
<h3 data-nodeid="7697">数据提取 — 过滤出我们需要的信息</h3>
<h4 data-nodeid="7698">初步分析</h4>
<p data-nodeid="7699">从之前学习的数据抓取一讲中我们学习到，要使用 BeautifulSoup 来提取数据，第一步首先应该分析我们想要的内容周围的标签结构，然后根据标签的层级关系来设计如何提取信息。</p>
<p data-nodeid="7700">还是从第一页的 html 开始，打开 htmls/tv1.html ，搜索“决胜法庭”，定位到第一个电视剧的标签部分。可以看到在一个 class 为 myui-vodlist__box 的 div 标签内部，基本包含了我们想要拿的所有信息，如下图所示。</p>
<p data-nodeid="32091" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKgxeAVj7vAAIDUCs0Qhs919.png" alt="Drawing 11.png" data-nodeid="32094"></p>

<p data-nodeid="7702">结合上图的分析，我们数据提取的思路大致是这样的。</p>
<ul data-nodeid="7703">
<li data-nodeid="7704">
<p data-nodeid="7705">获取所有 class=myui-vodlist__box 的 div 标签对象。</p>
</li>
<li data-nodeid="7706">
<p data-nodeid="7707">针对每一个标签对象，都尝试：</p>
<ul data-nodeid="7708">
<li data-nodeid="7709">
<p data-nodeid="7710">查找 h4 标签，并获得标签内的文本→电视剧名称；</p>
</li>
<li data-nodeid="7711">
<p data-nodeid="7712">查找 class = "pic-tag pic-tag-top" 的 span 标签，获得标签内文本→评分；</p>
</li>
<li data-nodeid="7713">
<p data-nodeid="7714">查找 p 标签，并获得标签内文本 → 演员信息。</p>
</li>
</ul>
</li>
</ul>
<p data-nodeid="7715">因为在外层标签内部，h4 标签和 p 标签都只有一个，所以不需要更多的过滤条件。</p>
<h4 data-nodeid="7716">提取单个 HTML 的所有电视剧信息</h4>
<p data-nodeid="7717">接下来，我们就开始编写从单个 html 文件抽取电视剧信息的代码，单个文件处理写完后扩展到多个就比较容易了。</p>
<p data-nodeid="7718">此处我们要用到在第 9 讲整理的，直接从文件名创建 BeautifulSoup 对象的函数：create_doc_from_filename。</p>
<p data-nodeid="7719">新建 Cell， 先将这个函数搬过来。</p>
<pre class="lang-python" data-nodeid="7720"><code data-language="python"><span class="hljs-keyword">from</span>&nbsp;bs4&nbsp;<span class="hljs-keyword">import</span>&nbsp;BeautifulSoup
<span class="hljs-comment">#&nbsp;输入参数为要分析的&nbsp;html&nbsp;文件名，返回值为对应的&nbsp;BeautifulSoup&nbsp;对象</span>
<span class="hljs-function"><span class="hljs-keyword">def</span>&nbsp;<span class="hljs-title">create_doc_from_filename</span>(<span class="hljs-params">filename</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;fo&nbsp;=&nbsp;open(filename,&nbsp;<span class="hljs-string">"r"</span>,&nbsp;encoding=<span class="hljs-string">'utf-8'</span>)
&nbsp;&nbsp;&nbsp;&nbsp;html_content&nbsp;=&nbsp;fo.read()
&nbsp;&nbsp;&nbsp;&nbsp;fo.close()
&nbsp;&nbsp;&nbsp;&nbsp;doc&nbsp;=&nbsp;BeautifulSoup(html_content)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span>&nbsp;doc
</code></pre>
<p data-nodeid="7721">之后根据初步分析中分析的步骤，实现内容的抓取。</p>
<p data-nodeid="7722">新建 Cell，输入如下代码：</p>
<pre class="lang-python" data-nodeid="7723"><code data-language="python"><span class="hljs-comment">#&nbsp;用&nbsp;tv1.html&nbsp;的内容创建&nbsp;BeautifulSoup&nbsp;对象</span>
doc&nbsp;=&nbsp;create_doc_from_filename(<span class="hljs-string">"htmls/tv1.html"</span>)
<span class="hljs-comment">#&nbsp;查找class="myui-vodlist__box"&nbsp;的所有&nbsp;div&nbsp;标签</span>
<span class="hljs-comment">#&nbsp;并以列表形式存储在&nbsp;box_list&nbsp;中</span>
box_list&nbsp;=&nbsp;doc.find_all(<span class="hljs-string">"div"</span>,&nbsp;class_=<span class="hljs-string">"myui-vodlist__box"</span>)
<span class="hljs-comment">#&nbsp;使用遍历循环遍历&nbsp;box_list&nbsp;中的所有标签对象</span>
<span class="hljs-keyword">for</span>&nbsp;box&nbsp;<span class="hljs-keyword">in</span>&nbsp;box_list:
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;根据上述分析的思路，分别获取包含标题、评分、和演员信息的标签</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;因为&nbsp;find_all&nbsp;总是返回列表，所以需要通过下标&nbsp;0&nbsp;来取第一个</span>
&nbsp;&nbsp;&nbsp;&nbsp;title_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"h4"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;rating_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"span"</span>,&nbsp;class_=<span class="hljs-string">"pic-tag&nbsp;pic-tag-top"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;stars_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"p"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;分别获取标签内部包含的文本，存储在&nbsp;title,&nbsp;rating,&nbsp;stars&nbsp;变量中</span>
&nbsp;&nbsp;&nbsp;&nbsp;title&nbsp;=&nbsp;title_label.text
&nbsp;&nbsp;&nbsp;&nbsp;rating&nbsp;=&nbsp;rating_label.text
&nbsp;&nbsp;&nbsp;&nbsp;stars&nbsp;=&nbsp;stars_label.text
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将获取的三个变量打印出来，看看是否正确。</span>
&nbsp;&nbsp;&nbsp;&nbsp;print(title,&nbsp;rating,&nbsp;stars)
</code></pre>
<p data-nodeid="7724">执行之后，输出如下（截取了部分日志）。可以看到我们想要的信息是有了，但是却好像带了很多没必要的空格。</p>
<pre class="lang-java" data-nodeid="7725"><code data-language="java">决胜法庭 
												<span class="hljs-number">3.7</span>分
											 
												主演于和伟,张佳宁,韩栋,王耀庆,连奕名,胡静,杜源,王艺禅,王全有
											
刘老根第三部 
												<span class="hljs-number">4.0</span>分
											 
												主演赵本山,范伟,李静,闫学晶,王小宝
											
我的僵尸王爷 
												<span class="hljs-number">4.6</span>分
											 
												主演内详
											
新世界<span class="hljs-number">2020</span> 
												<span class="hljs-number">3.4</span>分
											 
												主演孙红雷,张鲁一,尹昉,万茜,李纯,胡静,秦汉,赵峥,张瑶,张晔子
										
</code></pre>
<p data-nodeid="7726">有空格的原因是 html 页面中可能标签内部本来就有空格，但这好办，Python 的字符串有一个 strip 方法，可以去掉字符串前后的所有空格。</p>
<p data-nodeid="7727">我们修改一下代码，如下所示。</p>
<pre class="lang-python" data-nodeid="7728"><code data-language="python"><span class="hljs-comment">#&nbsp;用&nbsp;tv1.html&nbsp;的内容创建&nbsp;BeautifulSoup&nbsp;对象</span>
doc&nbsp;=&nbsp;create_doc_from_filename(<span class="hljs-string">"htmls/tv1.html"</span>)
<span class="hljs-comment">#&nbsp;查找class="myui-vodlist__box"&nbsp;的所有&nbsp;div&nbsp;标签</span>
<span class="hljs-comment">#&nbsp;并以列表形式存储在&nbsp;box_list&nbsp;中</span>
box_list&nbsp;=&nbsp;doc.find_all(<span class="hljs-string">"div"</span>,&nbsp;class_=<span class="hljs-string">"myui-vodlist__box"</span>)
<span class="hljs-comment">#&nbsp;使用遍历循环遍历&nbsp;box_list&nbsp;中的所有标签对象</span>
<span class="hljs-keyword">for</span>&nbsp;box&nbsp;<span class="hljs-keyword">in</span>&nbsp;box_list:
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;根据上述分析的思路，分别获取包含标题、评分、和演员信息的标签</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;因为&nbsp;find_all&nbsp;总是返回列表，所以需要通过下标&nbsp;0&nbsp;来取第一个</span>
&nbsp;&nbsp;&nbsp;&nbsp;title_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"h4"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;rating_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"span"</span>,&nbsp;class_=<span class="hljs-string">"pic-tag&nbsp;pic-tag-top"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;stars_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"p"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;分别获取标签内部包含的文本，存储在&nbsp;title,&nbsp;rating,&nbsp;stars&nbsp;变量中</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;【修改部分】并使用&nbsp;strip&nbsp;去除前后空格</span>
&nbsp;&nbsp;&nbsp;&nbsp;title&nbsp;=&nbsp;title_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;rating&nbsp;=&nbsp;rating_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;stars&nbsp;=&nbsp;stars_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将获取的三个变量打印出来，看看是否正确。</span>
&nbsp;&nbsp;&nbsp;&nbsp;print(title,&nbsp;rating,&nbsp;stars)
</code></pre>
<p data-nodeid="7729">再次执行代码，部分输出如下，可以看到这一次的数据已经很接近我们想要的样子了。</p>
<pre class="lang-java" data-nodeid="7730"><code data-language="java">决胜法庭 <span class="hljs-number">3.7</span>分 主演于和伟,张佳宁,韩栋,王耀庆,连奕名,胡静,杜源,王艺禅,王全有
刘老根第三部 <span class="hljs-number">4.0</span>分 主演赵本山,范伟,李静,闫学晶,王小宝
我的僵尸王爷 <span class="hljs-number">4.6</span>分 主演内详
新世界<span class="hljs-number">2020</span> <span class="hljs-number">3.4</span>分 主演孙红雷,张鲁一,尹昉,万茜,李纯,胡静,秦汉,赵峥,张瑶,张晔子
三生三世枕上书 <span class="hljs-number">4.4</span>分 主演迪丽热巴,高伟光,陈楚河,郭品超,刘雨欣,刘芮麟,王骁,李东恒,袁雨萱,黄俊捷
北灵少年志之大主宰 <span class="hljs-number">4.0</span>分 主演王源,欧阳娜娜,骆明劼,马月,徐浩,王奕婷
尖锋之烈焰青春 <span class="hljs-number">1.0</span>分 主演宋轶,李佳航,牛骏峰,孙洪涛,万沛鑫,侍宣如,赵圆瑗,吴谨言,钱志,一真
幸福院之老有所安 <span class="hljs-number">3.0</span>分 主演刘佩琦
鬼吹灯之牧野诡事 <span class="hljs-number">1.0</span>分 主演王大陆  金晨  王栎鑫
秘果 <span class="hljs-number">3.6</span>分 主演陈飞宇/欧阳娜娜
择天记 <span class="hljs-number">5.0</span>分 主演鹿晗/娜扎/吴倩/曾舜晞
欢乐颂<span class="hljs-number">2</span> <span class="hljs-number">1.0</span>分 主演刘涛/蒋欣/王子文/杨紫
关东大先生 <span class="hljs-number">4.0</span>分 主演赵本山,范伟,小沈阳,刘流
</code></pre>
<h4 data-nodeid="7731">提取多个 HTML 的内容</h4>
<p data-nodeid="7732">通过上述代码，我们已经可以将 tv1.html 文件中的所有电视剧信息给打印出来。但我们这次一共有一百个 html 文件，要怎么实现处理多个 html 文件呢？</p>
<p data-nodeid="7733">因为这一百个 HTML 文件虽然电视剧内容不一样，但是标签结构却是基本一样的（在电视剧网翻页的时候，可以看到每一页的样子都是一样的）。所以我们只需要将上面的代码放在循环中循环运行，然后每次循环都处理不同的 html 文件即可。</p>
<p data-nodeid="7734">为了让代码更加清晰，我们先将上面的处理单个文件的代码改写为函数，参数就是要处理的 html 文件名，函数则命名为：get_tv_from_html。</p>
<p data-nodeid="7735">新建 Cell，输入如下代码。</p>
<pre class="lang-python" data-nodeid="7736"><code data-language="python"><span class="hljs-comment">#&nbsp;从参数指定的&nbsp;html&nbsp;文件中获取电视剧的相关信息</span>
<span class="hljs-function"><span class="hljs-keyword">def</span>&nbsp;<span class="hljs-title">get_tv_from_html</span>(<span class="hljs-params">html_file_name</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;doc&nbsp;=&nbsp;create_doc_from_filename(html_file_name)
&nbsp;&nbsp;&nbsp;&nbsp;box_list&nbsp;=&nbsp;doc.find_all(<span class="hljs-string">"div"</span>,&nbsp;class_=<span class="hljs-string">"myui-vodlist__box"</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span>&nbsp;box&nbsp;<span class="hljs-keyword">in</span>&nbsp;box_list:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"h4"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rating_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"span"</span>,&nbsp;class_=<span class="hljs-string">"pic-tag&nbsp;pic-tag-top"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stars_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"p"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title&nbsp;=&nbsp;title_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rating&nbsp;=&nbsp;rating_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stars&nbsp;=&nbsp;stars_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将获取的三个变量打印出来，看看是否正确。</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(title,&nbsp;rating,&nbsp;stars)
<span class="hljs-comment">#&nbsp;试试用新写的函数处理一&nbsp;tv2.html</span>
get_tv_from_html(<span class="hljs-string">"htmls/tv2.html"</span>)
</code></pre>
<p data-nodeid="7737">输出节选如下。</p>
<pre class="lang-java" data-nodeid="7738"><code data-language="java">醉玲珑 <span class="hljs-number">5.0</span>分 主演 刘诗诗  陈伟霆  徐海乔  韩雪
河神 <span class="hljs-number">1.8</span>分 主演李现  张铭恩  王紫璇CiCi  陈芋米
少林问道 <span class="hljs-number">4.0</span>分 主演 周一围  郭京飞  郭晓婷  是安
鬼吹灯之黄皮子坟 <span class="hljs-number">3.0</span>分 主演阮经天  徐璐  郝好  刘潮  尚铁龙
槑头槑脑第二季 <span class="hljs-number">3.0</span>分 主演宋晓峰  霍云龙  程野
槑头槑脑 <span class="hljs-number">2.0</span>分 主演宋晓峰  霍云龙 唐艺兮 程野 唐娜
学生兵 <span class="hljs-number">2.0</span>分 主演张铎  孙艺宁  张光北  孙绍龙
绝密<span class="hljs-number">543</span> <span class="hljs-number">3.6</span>分 主演王聪  陈维涵  顾宇峰  王超
深海利剑 <span class="hljs-number">3.0</span>分 主演王强  高旻睿  刘璐  王阳
浪花一朵朵 <span class="hljs-number">5.0</span>分 主演谭松韵  熊梓淇  黄圣池  张峻宁
镇魂街[真人版] <span class="hljs-number">2.0</span>分 主演 汪东城 安悦溪 侯明昊
黑土热血 <span class="hljs-number">1.0</span>分 主演于毅,刘威葳,张芷溪,王劲松,曹克难,谭皓,侯煜,袁苑,齐千郡,山鹰,王今心
建军大业电视剧 <span class="hljs-number">4.0</span>分 主演黄海冰,郭广平,周惠林,李飞
颤抖吧，阿部 <span class="hljs-number">5.0</span>分 主演郑业成 安悦溪 王燕阳
</code></pre>
<p data-nodeid="7739">可以看到，我们成功用我们写的函数来从 tv2.html 中提取了电视剧的信息。这样要实现从一百个文件中抽取信息，只需要写一个循环，来每次传给 get_tv_from_html 函数不同的文件名即可。</p>
<p data-nodeid="7740">但现在还有一个问题，我们现在处理 html 之后，只是把我们要的信息打印了出来，打印在屏幕上显然是不满足做数据集的要求的。</p>
<p data-nodeid="7741">接下来，我们就来将所有信息保存为 csv 文件。</p>
<h3 data-nodeid="7742">数据保存 — 将我们的数据保存为 csv</h3>
<p data-nodeid="7743">回忆一下我们在第 09 讲学习的内容，要将数据保存为 csv 的记录，我们首先需要将每一行数据保存为字典,然后以一个字典列表的形式传递给 csv 模块的 DictWriter。</p>
<h4 data-nodeid="7744">（1）准备保存到 csv 的函数</h4>
<p data-nodeid="7745">为了让后续代码更简洁，我们先将把字典列表保存到 csv 文件的操作写成一个函数。</p>
<p data-nodeid="7746">新建 Cell，输入如下代码：</p>
<pre class="lang-python" data-nodeid="7747"><code data-language="python"><span class="hljs-comment">#&nbsp;导入&nbsp;csv&nbsp;模块</span>
<span class="hljs-keyword">import</span>&nbsp;csv
<span class="hljs-comment">#&nbsp;输入有三个参数：要保存的字典列表，csv&nbsp;文件名，和表头</span>
<span class="hljs-function"><span class="hljs-keyword">def</span>&nbsp;<span class="hljs-title">write_dict_list_to_csv</span>(<span class="hljs-params">dict_list,&nbsp;filename,&nbsp;headers</span>):</span>
    <span class="hljs-comment"># 当要处理的网页比较复杂时，增加 encoding 参数可以兼容部分特殊符号</span>
&nbsp;&nbsp;&nbsp;&nbsp;fo&nbsp;=&nbsp;open(filename,&nbsp;<span class="hljs-string">"w"</span>,&nbsp;newline=<span class="hljs-string">''</span>, encoding=<span class="hljs-string">'utf_8_sig'</span>)
&nbsp;&nbsp;&nbsp;&nbsp;writer&nbsp;=&nbsp;csv.DictWriter(fo,&nbsp;headers)
&nbsp;&nbsp;&nbsp;&nbsp;writer.writeheader()
&nbsp;&nbsp;&nbsp;&nbsp;writer.writerows(dict_list)
&nbsp;&nbsp;&nbsp;&nbsp;fo.close()
</code></pre>
<p data-nodeid="7748">实现的代码在第 09 讲也讲过，这里不再赘述。</p>
<h4 data-nodeid="7749">（2）创建保存所有电视剧字典的列表</h4>
<p data-nodeid="7750">我们需要一个列表来保存所有 html 文件中获取的电视剧信息。</p>
<p data-nodeid="7751">新建Cell， 输入如下代码并运行。</p>
<pre class="lang-python" data-nodeid="7752"><code data-language="python">all_tv_dict&nbsp;=&nbsp;[]
</code></pre>
<h4 data-nodeid="7753">（3）改造 get_tv_from_html 函数</h4>
<p data-nodeid="7754">我们在数据提取章节的末尾，实现了 get_tv_from_html 函数，可以方便地处理多个文件，但是当时只是把拿到了信息打印了出来。现在我们需要进行改造，不打印电视剧名、评分和演员信息，而是存储为字典。一个电视剧一个字典，而一个 html 文件中包含多个电视剧，所以 get_tv_from_html 最后会返回一个字典列表。</p>
<p data-nodeid="7755">回到 get_tv_from_html 的 cell，修改代码为如下所示，其中有修改的部分都标注了【新增】。</p>
<pre class="lang-python" data-nodeid="7756"><code data-language="python"><span class="hljs-comment">#&nbsp;从参数指定的&nbsp;html&nbsp;文件中获取电视剧的相关信息</span>
<span class="hljs-function"><span class="hljs-keyword">def</span>&nbsp;<span class="hljs-title">get_tv_from_html</span>(<span class="hljs-params">html_file_name</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;doc&nbsp;=&nbsp;create_doc_from_filename(html_file_name)
&nbsp;&nbsp;&nbsp;&nbsp;box_list&nbsp;=&nbsp;doc.find_all(<span class="hljs-string">"div"</span>,&nbsp;class_=<span class="hljs-string">"myui-vodlist__box"</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;【新增】当前处理的文件的字典列表</span>
&nbsp;&nbsp;&nbsp;&nbsp;tv_list&nbsp;=&nbsp;[]
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span>&nbsp;box&nbsp;<span class="hljs-keyword">in</span>&nbsp;box_list:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"h4"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rating_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"span"</span>,&nbsp;class_=<span class="hljs-string">"pic-tag&nbsp;pic-tag-top"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stars_label&nbsp;=&nbsp;box.find_all(<span class="hljs-string">"p"</span>)[<span class="hljs-number">0</span>]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title&nbsp;=&nbsp;title_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rating&nbsp;=&nbsp;rating_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stars&nbsp;=&nbsp;stars_label.text.strip()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;【新增】使用字典来保存，字典的&nbsp;key&nbsp;和&nbsp;csv&nbsp;的表头保持一致</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;【新增】在任务说明环节，表头为:&nbsp;title,&nbsp;rating,&nbsp;stars</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tv_dict&nbsp;=&nbsp;{}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tv_dict[<span class="hljs-string">"title"</span>]&nbsp;=&nbsp;title
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tv_dict[<span class="hljs-string">"rating"</span>]&nbsp;=&nbsp;rating
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tv_dict[<span class="hljs-string">"stars"</span>]&nbsp;=&nbsp;stars
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;【新增】将电视剧的字典添加到当前文件的字典列表中</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tv_list.append(tv_dict)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;【新增】返回字典列表</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span>&nbsp;tv_list
<span class="hljs-comment">#&nbsp;【新增】用最新修改的&nbsp;get_tv_from_html&nbsp;处理&nbsp;tv2.html，并将返回的结果存储在&nbsp;tv_list&nbsp;变量中</span>
tv_list&nbsp;=&nbsp;get_tv_from_html(<span class="hljs-string">"htmls/tv2.html"</span>)
<span class="hljs-comment">#&nbsp;【新增】打印获取到的列表</span>
print(tv_list)
</code></pre>
<p data-nodeid="7757">运行代码，输出节选如下所示。<br>
可以看到，这一次在 get_tv_from_html 中没有再进行输出，而是返回了字典列表。我们把字典列表打印了出来，其中的内容也就是我们想要的电视剧的信息。</p>
<pre class="lang-java" data-nodeid="7758"><code data-language="java">[{<span class="hljs-string">'title'</span>: <span class="hljs-string">'醉玲珑'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'5.0分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演 刘诗诗  陈伟霆  徐海乔  韩雪'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'河神'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'1.8分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演李现  张铭恩  王紫璇CiCi  陈芋米'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'少林问道'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'4.0分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演 周一围  郭京飞  郭晓婷  是安'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'鬼吹灯之黄皮子坟'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'3.0分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演阮经天  徐璐  郝好  刘潮  尚铁龙'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'槑头槑脑第二季'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'3.0分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演宋晓峰  霍云龙  程野'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'槑头槑脑'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'2.0分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演宋晓峰  霍云龙 唐艺兮 程野 唐娜'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'学生兵'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'2.0分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演张铎  孙艺宁  张光北  孙绍龙'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'绝密543'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'3.6分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演王聪  陈维涵  顾宇峰  王超'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'深海利剑'</span>, <span class="hljs-string">'rating'</span>: <span class="hljs-string">'3.0分'</span>, <span class="hljs-string">'stars'</span>: <span class="hljs-string">'主演王强  高旻睿  刘璐  王阳'</span>}, {<span class="hljs-string">'title'</span>: <span class="hljs-string">'浪花一朵朵'</span>, 
</code></pre>
<h4 data-nodeid="7759">（4）获取所有文件的电视剧信息</h4>
<p data-nodeid="7760">目前，我们通过 get_tv_from_file 函数，已经可以获取单个 html 的电视剧列表，现在我们需要通过一个循环，去处理所有的 html。对于每一个 html 文件，获取字典列表之后，都把列表添加到我们的总列表：all_tv_dict 中。这样，在循环执行结束后，all_tv_dict 变量中就包含了所有电视剧的信息。</p>
<p data-nodeid="7761">现在我们就来实现上面说的逻辑，新建 Cell，输入以下代码。</p>
<pre class="lang-python" data-nodeid="7762"><code data-language="python"><span class="hljs-comment">#&nbsp;因为是处理&nbsp;tv1-&nbsp;tv100&nbsp;的文件，所以i&nbsp;循环从1到101</span>
<span class="hljs-keyword">for</span>&nbsp;i&nbsp;<span class="hljs-keyword">in</span>&nbsp;range(<span class="hljs-number">1</span>,&nbsp;<span class="hljs-number">101</span>):
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;拼出每一次要处理的文件名</span>
&nbsp;&nbsp;&nbsp;&nbsp;file_name&nbsp;=&nbsp;<span class="hljs-string">"htmls/tv"</span>&nbsp;+&nbsp;str(i)&nbsp;+&nbsp;<span class="hljs-string">".html"</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;调用&nbsp;get_tv_from_html&nbsp;处理当次循环的文件</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将这个文件中的电视剧列表存储在&nbsp;dict_list&nbsp;变量</span>
&nbsp;&nbsp;&nbsp;&nbsp;dict_list&nbsp;=&nbsp;get_tv_from_html(file_name)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;将&nbsp;dict_list&nbsp;的内容添加到总列表&nbsp;all_tv_dict&nbsp;中</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;列表的拼接可以直接使用&nbsp;+&nbsp;号</span>
&nbsp;&nbsp;&nbsp;&nbsp;all_tv_dict&nbsp;=&nbsp;all_tv_dict&nbsp;+&nbsp;dict_list
<span class="hljs-comment">#&nbsp;打印出总列表的长度，看看我们一共抓取到了几部电视剧</span>
print(len(all_tv_dict))
</code></pre>
<p data-nodeid="7763">按 shift+enter 执行，因为要用 BeautifulSoup 处理一百个文件，这里执行会有点慢。需要耐心等一下，执行完毕后输出结果为 3600。</p>
<pre class="lang-java" data-nodeid="7764"><code data-language="java"><span class="hljs-number">3600</span>
</code></pre>
<p data-nodeid="7765">这说明我们一共抓取到了3600 部电视剧的信息。</p>
<h4 data-nodeid="7766">（5）保存结果到 csv 文件中</h4>
<p data-nodeid="7767">在任务说明中，已经明确了要保存的 csv 文件名为：tv_rating.csv, 表头为：title, rating, stars。</p>
<p data-nodeid="7768">现在，我们所有电视剧的信息都已经存储在 all_tv_dict 总列表中，现在我们只需要调用存储到 csv 的函数将其保存到 csv 文件即可。</p>
<pre class="lang-python" data-nodeid="7769"><code data-language="python"><span class="hljs-comment">#&nbsp;调用之前准备的&nbsp;write_dict_list_to_csv&nbsp;函数</span>
<span class="hljs-comment">#&nbsp;第一个参数为要保存的列表，这里就是我们存储了所有电视剧耳朵总列表&nbsp;all_tv_dict</span>
<span class="hljs-comment">#&nbsp;第二个参数为要保存的文件名</span>
<span class="hljs-comment">#&nbsp;第三个参数为要保存的&nbsp;csv&nbsp;文件的表头</span>
write_dict_list_to_csv(all_tv_dict,&nbsp;<span class="hljs-string">"tv_rating.csv"</span>,&nbsp;[<span class="hljs-string">"title"</span>,&nbsp;<span class="hljs-string">"rating"</span>,&nbsp;<span class="hljs-string">"stars"</span>])
</code></pre>
<p data-nodeid="7770">执行之后，没有内容输出，但是可以看到在 chapter10 文件夹下已经生成了 tv_rating.csv 文件。</p>
<p data-nodeid="33265" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/85/CioPOWCKgzWANRhLAAArMQ5hOKc286.png" alt="Drawing 12.png" data-nodeid="33268"></p>

<p data-nodeid="7772">使用 Excel 打开该 csv 文件，可以看到我们的表头已经正确写入，表头对应的内容也已经正确写入。</p>
<p data-nodeid="34439" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKgzyATlqBAAOll7Fghb0066.png" alt="Drawing 13.png" data-nodeid="34442"></p>

<p data-nodeid="7774">拉倒底部，可以看到最后一行记录是 3061，因为第一行是表头，所以我们最终保存了 3600 条电视剧的信息，这和之前我们列表的长度也对得上。</p>
<p data-nodeid="35613" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/85/CioPOWCKg0OASeccAAQR2CMZu-I452.png" alt="Drawing 14.png" data-nodeid="35616"></p>

<p data-nodeid="7776">至此，一份国产电视剧评分的数据集就制作完毕了。</p>
<p data-nodeid="7777">将数据集交给了数据分析部门的同事之后，大家都对你能够这么快就搞定这个任务感觉到刮目相看，Mentor 也露出了欣慰的笑容，想着是时候交给你更重要的任务了！</p>
<h3 data-nodeid="36787">小结</h3>


<p data-nodeid="7780">总结一下本讲的内容，今天这个实战基本上用到了这一模块我们学习的所有知识，主要包括：</p>
<ul data-nodeid="7781">
<li data-nodeid="7782">
<p data-nodeid="7783">根据数据集的要求选择所要抓取的网页；</p>
</li>
<li data-nodeid="7784">
<p data-nodeid="7785">实现单个页面抓取；</p>
</li>
<li data-nodeid="7786">
<p data-nodeid="7787">实现多个页面的抓取；</p>
</li>
<li data-nodeid="7788">
<p data-nodeid="7789">实现页面内容的提取；</p>
</li>
<li data-nodeid="7790">
<p data-nodeid="7791">将提取到的内容转化成字典列表，并保存到 csv 文件。</p>
</li>
</ul>
<p data-nodeid="7792">到现在，我们数据获取部分的内容就学习完毕了。下一模块，我们将学习 Python 数据分析最广泛使用的框架：pandas。</p>
<p data-nodeid="37957" class=""><strong data-nodeid="37961">课后习题</strong></p>

<p data-nodeid="7794">在刚才的 csv 中，演员一栏的内容都包含了“主演”两个字，是比较冗余的。请你编写代码，读取 tv_rating.csv 的内容，然后把每行记录的演员信息中的“主演”两个字删除，删完后新的内容保存至 tv_rating2.csv。</p>
<hr data-nodeid="7795">
<p data-nodeid="39136" class=""><strong data-nodeid="39141">答案</strong>：</p>

<p data-nodeid="7797">解题思路类似上一讲，我们先读取所有字典列表，通过一个循环遍历列表，对于每一个字典，通过 stars 这个key拿到演员信息，删除主演两个字后再存储回 stars 这个 key 对应的值中。</p>
<pre class="lang-python" data-nodeid="7798"><code data-language="python"><span class="hljs-comment">#&nbsp;整理读取&nbsp;CSV&nbsp;的代码为函数</span>
<span class="hljs-comment">#&nbsp;输入参数为&nbsp;CSV&nbsp;文件名，返回值为读取到的字典列表</span>
<span class="hljs-function"><span class="hljs-keyword">def</span>&nbsp;<span class="hljs-title">get_dict_list_from_csv</span>(<span class="hljs-params">filename</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;fo&nbsp;=&nbsp;open(filename,&nbsp;<span class="hljs-string">"r"</span>,&nbsp;encoding=<span class="hljs-string">"utf_8_sig"</span>)
&nbsp;&nbsp;&nbsp;&nbsp;reader&nbsp;=&nbsp;csv.DictReader(fo)
&nbsp;&nbsp;&nbsp;&nbsp;dict_list&nbsp;=&nbsp;[]
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span>&nbsp;item&nbsp;<span class="hljs-keyword">in</span>&nbsp;reader:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dict_list.append(item)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span>&nbsp;dict_list
<span class="hljs-comment">#&nbsp;读取&nbsp;tv_rating.csv&nbsp;文件，并将返回的字典列表赋值给&nbsp;tv_list1&nbsp;变量</span>
tv_list1&nbsp;=&nbsp;get_dict_list_from_csv(<span class="hljs-string">"tv_rating.csv"</span>)
<span class="hljs-comment">#&nbsp;遍历循环&nbsp;tv_list1&nbsp;</span>
<span class="hljs-keyword">for</span>&nbsp;item&nbsp;<span class="hljs-keyword">in</span>&nbsp;tv_list1:
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;针对每个字典，将&nbsp;stars&nbsp;对应的value&nbsp;的“主演”&nbsp;替换为空，也就是删除主演两个字</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#&nbsp;并将结果存回&nbsp;item&nbsp;字典</span>
&nbsp;&nbsp;&nbsp;&nbsp;item[<span class="hljs-string">"stars"</span>]&nbsp;=&nbsp;item[<span class="hljs-string">"stars"</span>].replace(<span class="hljs-string">"主演"</span>,<span class="hljs-string">""</span>)
<span class="hljs-comment">#&nbsp;将修改之后的列表重新写到&nbsp;tv_rating2.csv&nbsp;中</span>
write_dict_list_to_csv(tv_list1,&nbsp;<span class="hljs-string">"tv_rating2.csv"</span>,&nbsp;[<span class="hljs-string">"title"</span>,&nbsp;<span class="hljs-string">"rating"</span>,&nbsp;<span class="hljs-string">"stars"</span>])
</code></pre>
<p data-nodeid="41502">运行之后，可以看到生成了 tv_rating2.csv 打开后如下所示，可以看到“主演”二字都已经删除了。</p>
<p data-nodeid="41503" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M01/3C/7C/Cgp9HWCKg1mAdlqfAAOZcm0uHPY695.png" alt="Drawing 15.png" data-nodeid="41509"></p>

---

### 精选评论


